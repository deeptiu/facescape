{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from imutils import face_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "image = cv2.imread(\"/home/dupmaka/2D+3D/F001/T1/0000.jpg\")\n",
    "# image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# detect faces in the grayscale image\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "\n",
    "# loop over the face detections\n",
    "for (i, rect) in enumerate(rects):\n",
    "\t# determine the facial landmarks for the face region, then\n",
    "\t# convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "\t# array\n",
    "\tshape = predictor(gray, rect)\n",
    "\tshape = face_utils.shape_to_np(shape)\n",
    "\t# convert dlib's rectangle to a OpenCV-style bounding box\n",
    "\t# [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "\t(x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t# show the face number\n",
    "\tcv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\t# loop over the (x, y)-coordinates for the facial landmarks\n",
    "\t# and draw them on the image\n",
    "\tfor (x, y) in shape:\n",
    "\t\tcv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "# show the output image with the face detections + facial landmarks\n",
    "cv2.imwrite(\"sample.jpg\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[377 779] [688 778]\n",
      "[ 435 1060] [ 610 1085]\n",
      "(1392, 1040, 3)\n"
     ]
    }
   ],
   "source": [
    "# get two points, 38, 45 on the left and right eye \n",
    "# 49 left mouth, 55 right mouth\n",
    "\n",
    "image = cv2.imread(\"/home/dupmaka/2D+3D/F001/T1/0000.jpg\")\n",
    "shape = predictor(gray, rects[0])\n",
    "shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "left_eye = shape[37]\n",
    "right_eye = shape[44]\n",
    "left_mouth = shape[48]\n",
    "right_mouth = shape[55]\n",
    "\n",
    "print(left_eye, right_eye)\n",
    "print(left_mouth, right_mouth)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 20 32] [20 17 33] [ 46  60 102] [ 48  52 103]\n",
      "1392 1040\n"
     ]
    }
   ],
   "source": [
    "color_left = image[left_eye[1], left_eye[0]]\n",
    "color_right = image[right_eye[1], right_eye[0]]\n",
    "color_left_mouth = image[left_mouth[1], left_mouth[0]]\n",
    "color_right_mouth = image[right_mouth[1], right_mouth[0]]\n",
    "print(color_left, color_right, color_left_mouth, color_right_mouth)\n",
    "\n",
    "print(image.shape[0], image.shape[1])\n",
    "left_eye_norm = np.array([left_eye[0]/image.shape[0], left_eye[1]/image.shape[1]])\n",
    "right_eye_norm = np.array([right_eye[0]/image.shape[0], right_eye[1]/image.shape[1]])\n",
    "left_mouth_norm = np.array([left_mouth[0]/image.shape[0], left_mouth[1]/image.shape[1]])\n",
    "right_mouth_norm = np.array([right_mouth[0]/image.shape[0], right_mouth[1]/image.shape[1]])\n",
    "\n",
    "# print(left_eye_norm, right_eye_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43436, 2)\n",
      "(43436,) (43436,)\n",
      "[377 779] [688 778]\n",
      "[377 779] [688 778]\n",
      "[  65.58623505   93.16883087 -130.48225403] [  97.90278625   66.4495163  -130.39753723]\n",
      "[  52.75791168  100.61457825 -131.60823059] [  65.58623505   93.16883087 -130.48225403]\n"
     ]
    }
   ],
   "source": [
    "import pyrender, trimesh, cv2, openmesh, os\n",
    "\n",
    "mesh = openmesh.read_trimesh(\"/home/dupmaka/2D+3D/F001/T1/0000.obj\", vertex_tex_coord=True, face_color=True) \n",
    "verts = mesh.points()\n",
    "\n",
    "tex = []\n",
    "\n",
    "for i, vh in enumerate(mesh.vertices()):                                                                                                                                    \n",
    "    tex.append(mesh.texcoord2D(vh))\n",
    "\n",
    "tex = np.array(tex)\n",
    "print(tex.shape)\n",
    "left_eye_repeated = np.repeat(np.array([left_eye]), tex.shape[0], axis=0)\n",
    "right_eye_repeated = np.repeat(np.array([right_eye]), tex.shape[0], axis=0)\n",
    "left_mouth_repeated = np.repeat(np.array([left_mouth]), tex.shape[0], axis=0)\n",
    "right_mouth_repeated = np.repeat(np.array([right_mouth]), tex.shape[0], axis=0)\n",
    "\n",
    "diff_left = np.linalg.norm(tex-left_eye_repeated, axis=1)\n",
    "diff_right = np.linalg.norm(tex-right_eye_repeated, axis=1)\n",
    "diff_left_mouth = np.linalg.norm(tex-left_mouth_repeated, axis=1)\n",
    "diff_right_mouth = np.linalg.norm(tex-right_mouth_repeated, axis=1)\n",
    "\n",
    "print(diff_left.shape, diff_right.shape)\n",
    "\n",
    "left_vert_idx = np.argmin(diff_left)\n",
    "right_vert_idx = np.argmin(diff_right)\n",
    "left_mouth_vert_idx = np.argmin(diff_left_mouth)\n",
    "right_mouth_vert_idx = np.argmin(diff_right_mouth)\n",
    "\n",
    "print(left_eye, right_eye)\n",
    "\n",
    "left_vert = verts[left_vert_idx]\n",
    "right_vert = verts[right_vert_idx]\n",
    "left_mouth_vert = verts[left_mouth_vert_idx]\n",
    "right_mouth_vert = verts[right_mouth_vert_idx]\n",
    "\n",
    "print(left_eye, right_eye)\n",
    "print(left_vert, right_vert)\n",
    "print(left_mouth_vert, right_mouth_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n",
      "PolyMeshT::add_face: complex vertex\n"
     ]
    }
   ],
   "source": [
    "# get the points that corresond to same locations on the facescape mesh model\n",
    "\n",
    "import pyrender, trimesh, cv2, openmesh, os\n",
    "import numpy as np\n",
    "import src.renderer as renderer\n",
    "import src.camera as camera\n",
    "import src.utility as util\n",
    "\n",
    "# read model \n",
    "model = trimesh.load_mesh(\"/home/dupmaka/facescape_old/toolkit/demo_output/original_mesh.obj\", process=False)\n",
    "\n",
    "# get vertices using openmesh, because trimesh doesn't preserve vertex number and order\n",
    "om_mesh = openmesh.read_trimesh(\"/home/dupmaka/facescape_old/toolkit/demo_output/original_mesh.obj\") \n",
    "verts = om_mesh.points()\n",
    "\n",
    "# set material\n",
    "# model.visual.material.diffuse = np.array([255, 255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# # set K Rt (cv camera coordinate)\n",
    "# K = np.array([[2000, 0 , 499.5],\n",
    "#               [0, 2000, 499.5],\n",
    "#               [0, 0, 1]])\n",
    "# Rt = np.array([[1, 0 , 0, 0],\n",
    "#                [0, -1, 0, 0],\n",
    "#                [0, 0, -1, 600]])\n",
    "\n",
    "# # render\n",
    "# _, color = renderer.render_cvcam(model, K, Rt, scale=1.0, \n",
    "#                                  rend_size=(1000, 1000), flat_shading=False)\n",
    "\n",
    "# # read landmark indices, 'v16' is for bilinear model 1.6 and later versions\n",
    "# lm_list_v16 = np.load(\"./predef/landmark_indices.npz\")['v16']\n",
    "\n",
    "# # make camera for projection\n",
    "# cam = camera.CamPara(K = K, Rt = Rt)\n",
    "\n",
    "# # draw landmarks\n",
    "# color_draw = color.copy()\n",
    "# for ind, lm_ind in enumerate(lm_list_v16):\n",
    "#     uv = cam.project(verts[lm_ind])\n",
    "#     u, v = np.round(uv).astype(np.int)\n",
    "#     color_draw = cv2.circle(color_draw, (u, v), 10, (100, 100, 100), -1)\n",
    "#     color_draw = cv2.putText(color_draw, \"%02d\"%(ind), (u-8, v+4), \n",
    "#                              fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                              fontScale = 0.4,\n",
    "#                              color = (255, 255, 255))\n",
    "\n",
    "# util.show_img_arr(color_draw, bgr_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points from the bilinear model \n",
    "left_eye_fs = [-9.511489705882353318e-02, -1.171094999999999775e-01, 2.978996264705880748e+00]\n",
    "right_eye_fs = [9.475910294117646793e-02, -1.038524999999999726e-01, 2.956299264705880780e+00] \n",
    "left_mouth_fs = [-6.529089705882352990e-02, 8.611350000000000948e-02, 3.009020264705880798e+00]\n",
    "right_mouth_fs = [6.172010294117646900e-02, 9.618150000000003086e-02, 2.990527264705881372e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  65.58623505,   93.16883087, -130.48225403]), array([  97.90278625,   66.4495163 , -130.39753723]), array([  52.75791168,  100.61457825, -131.60823059]), array([  65.58623505,   93.16883087, -130.48225403])]\n",
      "[[-0.09511489705882353, -0.11710949999999998, 2.9789962647058807], [0.09475910294117647, -0.10385249999999997, 2.956299264705881], [-0.06529089705882353, 0.08611350000000001, 3.009020264705881], [0.06172010294117647, 0.09618150000000003, 2.9905272647058814]]\n",
      "[[0.09511489705882353, 0.11710949999999998, -1, 0, 0, 0, -6.238227994912877, -7.680771193164824, 65.58623504638672], [0, 0, 0, 0.09511489705882353, 0.11710949999999998, -1, -8.861743757441465, -10.910955198955534, 93.16883087158203], [-0.09475910294117647, 0.10385249999999997, -1, 0, 0, 0, 9.277180200954437, -10.167449109535214, 97.90278625488281], [0, 0, 0, -0.09475910294117647, 0.10385249999999997, -1, 6.296696555120692, -6.9009483911705, 66.44951629638672], [0.06529089705882353, -0.08611350000000001, -1, 0, 0, 0, -3.4446113806763816, 4.543168427639008, 52.757911682128906], [0, 0, 0, 0.06529089705882353, -0.08611350000000001, -1, -6.569216070946413, 8.664273483879091, 100.61457824707031], [-0.06172010294117647, -0.09618150000000003, -1, 0, 0, 0, 4.047989178587184, 6.308182466114046, 65.58623504638672], [0, 0, 0, -0.06172010294117647, -0.09618150000000003, -1, 5.750389832303103, 8.96111790647507, 93.16883087158203]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matrix shape ((3, 3)) doesn't match points ((43436, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dupmaka/facescape_old/toolkit/landmarks.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgenos.ri.cmu.edu/home/dupmaka/facescape_old/toolkit/landmarks.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m H \u001b[39m=\u001b[39m vt[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:,:]\u001b[39m.\u001b[39mreshape((\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgenos.ri.cmu.edu/home/dupmaka/facescape_old/toolkit/landmarks.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m initial \u001b[39m=\u001b[39m H \u001b[39m#np.array([[1., 0., 0., dist[0]], [0., 1., 0., dist[1]], [0., 0., 1., dist[2]], [0., 0., 0., 1.]])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgenos.ri.cmu.edu/home/dupmaka/facescape_old/toolkit/landmarks.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m matrix, transformed, cost \u001b[39m=\u001b[39m trimesh\u001b[39m.\u001b[39;49mregistration\u001b[39m.\u001b[39;49micp(mesh\u001b[39m.\u001b[39;49mpoints(), om_mesh\u001b[39m.\u001b[39;49mpoints(), initial)\n",
      "File \u001b[0;32m~/.conda/envs/l3d/lib/python3.9/site-packages/trimesh/registration.py:313\u001b[0m, in \u001b[0;36micp\u001b[0;34m(a, b, initial, threshold, max_iterations, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     btree \u001b[39m=\u001b[39m cKDTree(b)\n\u001b[1;32m    312\u001b[0m \u001b[39m# transform a under initial_transformation\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m a \u001b[39m=\u001b[39m transform_points(a, initial)\n\u001b[1;32m    314\u001b[0m total_matrix \u001b[39m=\u001b[39m initial\n\u001b[1;32m    316\u001b[0m \u001b[39m# start with infinite cost\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/l3d/lib/python3.9/site-packages/trimesh/transformations.py:2130\u001b[0m, in \u001b[0;36mtransform_points\u001b[0;34m(points, matrix, translate)\u001b[0m\n\u001b[1;32m   2127\u001b[0m matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(matrix, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m   2128\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(points\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m         (points\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m!=\u001b[39m matrix\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])):\n\u001b[0;32m-> 2130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mmatrix shape (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt match points (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2131\u001b[0m         matrix\u001b[39m.\u001b[39mshape,\n\u001b[1;32m   2132\u001b[0m         points\u001b[39m.\u001b[39mshape))\n\u001b[1;32m   2134\u001b[0m \u001b[39m# check to see if we've been passed an identity matrix\u001b[39;00m\n\u001b[1;32m   2135\u001b[0m identity \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(matrix \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39meye(matrix\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mmax()\n",
      "\u001b[0;31mValueError\u001b[0m: matrix shape ((3, 3)) doesn't match points ((43436, 3))"
     ]
    }
   ],
   "source": [
    "# IPC with the sampled points \n",
    "\n",
    "# left_vert\n",
    "# right_vert\n",
    "# left_eye_fs\n",
    "# right_eye_fs\n",
    "\n",
    "dist = left_eye_fs-left_vert\n",
    "\n",
    "# # bp4d\n",
    "# mesh\n",
    "\n",
    "# # facescape\n",
    "# om_mesh\n",
    "\n",
    "# set up homography DLT\n",
    "points = [left_vert, right_vert, left_mouth_vert, right_mouth_vert]\n",
    "print(points)\n",
    "img_points = [left_eye_fs, right_eye_fs, left_mouth_fs, right_mouth_fs]\n",
    "print(img_points)\n",
    "\n",
    "A = []\n",
    "for i in range(4):\n",
    "    # x,y will be image points\n",
    "    x = points[i][0]\n",
    "    y = points[i][1]\n",
    "    \n",
    "    # x_prime,y_prime will be corresponding points\n",
    "    x_prime = img_points[i][0]\n",
    "    y_prime = img_points[i][1]\n",
    "    \n",
    "    A_eq_1 = [-x_prime, -y_prime, -1, 0, 0, 0, x*x_prime, x*y_prime, x] \n",
    "    A.append(A_eq_1)\n",
    "    A_eq_2 = [0, 0, 0, -x_prime, -y_prime, -1, y*x_prime, y*y_prime, y]\n",
    "    A.append(A_eq_2)\n",
    "    \n",
    "u, s, vt = np.linalg.svd(A)\n",
    "\n",
    "H = vt[-1:,:].reshape((3,3))\n",
    "\n",
    "initial = np.array([[1., 0., 0., dist[0]], [0., 1., 0., dist[1]], [0., 0., 1., dist[2]], [0., 0., 0., 1.]])\n",
    "\n",
    "matrix, transformed, cost = trimesh.registration.icp(mesh.points(), om_mesh.points(), initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dupmaka/.conda/envs/l3d/lib/python3.9/site-packages/iopath/common/file_io.py\", line 946, in __log_tmetry_keys\n",
      "    handler.log_event()\n",
      "  File \"/home/dupmaka/.conda/envs/l3d/lib/python3.9/site-packages/iopath/common/event_logger.py\", line 97, in log_event\n",
      "    del self._evt\n",
      "AttributeError: _evt\n",
      "An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dupmaka/.conda/envs/l3d/lib/python3.9/site-packages/iopath/common/file_io.py\", line 946, in __log_tmetry_keys\n",
      "    handler.log_event()\n",
      "  File \"/home/dupmaka/.conda/envs/l3d/lib/python3.9/site-packages/iopath/common/event_logger.py\", line 97, in log_event\n",
      "    del self._evt\n",
      "AttributeError: _evt\n"
     ]
    }
   ],
   "source": [
    "import pytorch3d \n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "import torch\n",
    "\n",
    "# print(type(transformed))\n",
    "# print(type(om_mesh.faces()))\n",
    "\n",
    "torch_transformed = torch.from_numpy(transformed)\n",
    "\n",
    "# print(type(torch_transformed))\n",
    "vertices, faces, _ = load_obj(\"/home/dupmaka/facescape_old/toolkit/demo_output/original_mesh.obj\")\n",
    "\n",
    "# print(type(vertices))\n",
    "\n",
    "pytorch3d.io.save_obj(\"test.obj\", torch_transformed, faces.verts_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('l3d': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bcb139a976f34a78012a033e8d2464d901965a486e07a5456fd811cfd0667fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
